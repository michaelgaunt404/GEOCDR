)
recipe = titanic_train %>%
recipe(survived ~ .) %>%
step_unknown(all_nominal()) %>%
step_medianimpute(all_numeric()) %>%
step_dummy(all_nominal(), -survived, one_hot = TRUE)
engine_tidym <- rand_forest(
mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 30)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
install.packages("ranger")
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
data("credit_data")
engine_tidym <- rand_forest(
mode = "classification",
mtry = 8,
trees = 600,
min_n = 3) %>%
set_engine("ranger", importance = "impurity")
engine_tidym
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
# grid = gridy_tidym,
metrics = metric_set(roc_auc),
# control = control_grid(save_pred = TRUE)
)
#data inport~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
titanic %>% skim()
recipe = titanic_train %>%
recipe(survived ~ .) %>%
step_unknown(all_nominal(), -survived) %>%
step_medianimpute(all_numeric()) %>%
step_dummy(all_nominal(), -survived, one_hot = TRUE)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
# grid = gridy_tidym,
metrics = metric_set(roc_auc),
# control = control_grid(save_pred = TRUE)
)
grid_tidym
grid_tidym[1,1]
grid_tidym[1,1] %>%  unnest(data = .)
grid_tidym[1,1] %>%  unnest(cols = c(splits))
grid_tidym[1,1] %>%  unnest(cols = c("splits"))
grid_tidym[1,] %>%  unnest(cols = c("splits"))
grid_tidym[1,] %>%  unnest(cols = "splits")
grid_tidym[1,] %>%  unnest(cols = splits)
grid_tidym %>%  unnest(cols = splits)
grid_tidym %>%  unnest(cols = "splits")
grid_tidym %>%  unnest(cols = c("splits"))
grid_tidym
grid_tidym[1,]
grid_tidym[1,] %>%  unnest(cols = 'splits')
grid_tidym %>%  collect_metrics()
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
gridy_tidym
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
# control = control_grid(save_pred = TRUE)
)
grid_tidym
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
grid_tidym
grid_tidym %>%  collect_metrics()
grid_tidym
grid_tidym %>%  collect_metrics()
recipe = titanic_train %>%
recipe(survived ~ .) %>%
step_unknown(all_nominal(), -survived) %>%
step_medianimpute(all_numeric()) %>%
step_dummy(all_nominal(), -survived, one_hot = TRUE)
engine_tidym <- rand_forest(
mode = "classification",
mtry = 8,
trees = 600,
min_n = 3) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
grid_tidym %>%  collect_metrics()
select_best(grid_tidym)
gridy_tidym
train_cv
train_cv <- vfold_cv(titanic_train, v = 5)
recipe = titanic_train %>%
recipe(survived ~ .) %>%
step_unknown(all_nominal(), -survived) %>%
step_medianimpute(all_numeric()) %>%
step_dummy(all_nominal(), -survived, one_hot = TRUE)
engine_tidym <- rand_forest(
mode = "classification",
mtry = 8,
trees = 600,
min_n = 3) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
titanic_train
engine_tidym <- rand_forest(
mode = "classification",
mtry = 8,
trees = 600,
min_n = 3) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
gridy_tidym
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE))
train_cv <- vfold_cv(titanic_train, v = 5, strata = survived)
train_cv
unnest(train_cv, cols = "splits")
train_cv %>%
mutate(anal = map(splits, assessment))
train_cv %>%
mutate(response = map(splits, assessment),
breakdown = map(response, tabyl, survived))
train_cv %>%
mutate(response = map(splits, assessment),
breakdown = map(response, tabyl, survived)) %>%
unnest(beakdown)
train_cv %>%
mutate(response = map(splits, assessment),
breakdown = map(response, tabyl, survived)) %>%
unnest(cols = breakdown)
train_cv <- vfold_cv(titanic_train, v = 5)
train_cv %>%
mutate(response = map(splits, assessment),
breakdown = map(response, tabyl, survived)) %>%
unnest(cols = breakdown)
train_cv <- vfold_cv(titanic_train, v = 5, strata = survived)
recipe = titanic_train %>%
recipe(survived ~ .) %>%
step_unknown(all_nominal(), -survived) %>%
step_medianimpute(all_numeric()) %>%
step_dummy(all_nominal(), -survived, one_hot = TRUE)
engine_tidym <- rand_forest(
mode = "classification",
mtry = 8,
trees = 600,
min_n = 3) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE))
grid_tidym %>%  collect_metrics()
grid_tidym
mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE))
grid_tidym
grid_tidym %>%  collect_metrics()
engine_tidym <- rand_forest(
mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()) %>%
set_engine("ranger", importance = "impurity")
gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 10)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE))
grid_tidym
grid_tidym %>%  collect_metrics()
select_best(grid_tidym)
best = select_best(grid_tidym)
best
(wkfl_tidym_best <- finalize_workflow(wkfl_tidym, grid_tidym_best))
(wkfl_tidym_best <- finalize_workflow(wkfl_tidym, best))
(wkfl_tidym_final <- last_fit(wkfl_tidym_best, split = split))
wkfl_tidym_best
(wkfl_tidym_final <- last_fit(wkfl_tidym_best, split = titanic_init_split ))
wkfl_tidym_final
wkfl_tidym_final
wkfl_tidym_final
grid_tidym
grid_tidym %>%  collect_metrics()
final_mdl = wkfl_tidym_best %>%
fit(data = titanic_train)
final_mdl
library("rms")
final_mdl = wkfl_tidym_best %>%
fit(data = titanic_test)
final_mdl
wkfl_tidym_final %>%
collect_metrics()
wkfl_tidym_final %>%
collect_predictions()
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(class, .pred_PS) %>%
autoplot()
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(survived, .pred_class) %>%
autoplot()
final_fit %>%
collect_predictions()
wkfl_tidym_final %>%
collect_predictions()
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(.pred_yes, .pred_class) %>%
autoplot()
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(survived, .pred_no)
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(survived, .pred_no) %>%
autoplot()
wkfl_tidym_final %>%
collect_predictions() %>%
roc_curve(survived, .pred_yes) %>%
autoplot()
shiny::runApp('~/040_projects/geocodr/app')
runApp('~/040_projects/geocodr/app')
dr_here()
addresses = fread("./data/addresses.csv")
library(magrittr)
library(readxl)
library(data.table)
library(tidyverse)
library(hereR)
library(tictoc)
library(furrr)
future::plan(multiprocess)
#path and data set-up~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
if (!exists("BEING_SOURCED_FROM_SOMEWHERE")){
setwd("~/")
rstudioapi::getSourceEditorContext()$path %>%
as.character() %>%
gsub("R.*","\\1", .) %>%
path.expand() %>%
setwd()
}
#sourcing script~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# if (!exists("Kept_Extracted_Data")) {
#   print("F I L E    S O U R C E D")
suppressMessages({
suppressWarnings({
source("./R/utility.R")
})
})
#link extraction~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~making SF objects
set_key(secret_key[[1]])
set_verbose(TRUE)
addresses = fread("./data/addresses.csv")
addresses
addresses = fread("./data/addresses.csv", header = T)
addresses
addresses = fread("./data/addresses.csv", header = T)
addresses = read.csv("./data/addresses.csv", header = T)
addresses
geocoded <- geocode(addresses, autocomplete = FALSE)
geocoded <- geocode(addresses$Address, autocomplete = FALSE)
str(addresses)
addresses = read.csv("./data/addresses.csv", header = T, stringsAsFactors = F)
geocoded <- geocode(addresses$Address, autocomplete = FALSE)
tmp
geocoded
library(tmap)
tm_shape(geocoded) +
tm_dots()
tmap_mode('view', verbose = F)
tmap_mode('view')
tm_shape(geocoded) +
tm_dots()
geocoded
addresses = read.csv("./data/addresses.csv", header = T, stringsAsFactors = F)
addresses
addresses = read.csv("./data/addresses.csv", header = T, stringsAsFactors = F) %>%
janitor::remove_constant()
addresses
addresses = read.csv("./data/addresses.csv", header = T, stringsAsFactors = F) %>%
janitor::remove_constant() %>%
str_trim()
addresses = read.csv("./data/addresses.csv", header = T, stringsAsFactors = F) %>%
janitor::remove_constant() %>%
mutate(Address = Address %>%  str_trim())
addresses
geocoded <- geocode(addresses$Address, autocomplete = FALSE)
geocoded %>%  tm_shape() +
tm_dots()
geocoded
addresses
"S State St & W Madison St, Chicago, IL 60603, United States" %>%
geocode(autocomplete = FALSE)
poi
tm_shape(poi) +
tm_dots()
reverse_geocode(poi, results = 1, landmarks = FALSE, url_only = FALSE)
reverse = reverse_geocode(poi, results = 1, landmarks = FALSE, url_only = FALSE)
reverse %>%
reverse %>%
tm_shape() +
tm_dots()
reverse = reverse_geocode(poi, results = 1, landmarks = FALSE, url_only = FALSE)
reverse
reverse %>%
tm_shape() +
tm_dots()
poi[1:2, ]
poi[3:4, ]
routeee = route(poi[1:2, ], poi[3:4, ], mode = "car")
routeee
routeee %>% tm_shape() %>%
tm_lines()
routeee %>% tm_shape() +
tm_lines()
routeee
routeee %>%
tm_shape(col = "origin") +
tm_lines() +
tm_shape(poi[1:4, ]) +
tm_lines()
routeee %>%
tm_shape(col = "origin") +
tm_lines() +
tm_shape(poi[1:4, ]) +
tm_dots()
routeee %>%
tm_shape(col = "origin") +
tm_lines()
routeee %>%
tm_shape() +
tm_lines(col = "distance") +
tm_shape(poi[1:4, ]) +
tm_dots()
routeee %>%
tm_shape() +
tm_lines(col = "distance",
style = "fixed") +
tm_shape(poi[1:4, ]) +
tm_dots()
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
library(janitor)
library(hereR)
runApp()
library(DT)
library(DT)
runApp('app')
runApp('app')
runApp('app')
runApp('app')
geocoded
geocoded <- geocode(addresses$Address, autocomplete = FALSE)
message(geocoded)
evaluate::evaluate(geocoded)
withCallingHandlers(geocoded)
geocoded <- withCallingHandlers(geocode(addresses$Address, autocomplete = FALSE))
geocoded
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp()
runApp('app')
runApp('app')
runApp()
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
library(leaflet)
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('scratch')
runApp('scratch')
runApp('scratch')
runApp('app')
set_key("sjjsjsjsjsjsjsjsjsjs")
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
